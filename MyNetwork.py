# -*- coding: utf-8 -*-
"""MyNetwork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iwL55k8dQGNiTQx4nnvgfFYgIJmURKyI
"""

import numpy as n
import torch
import torchvision.models as models
import torch.nn as nn
from torch.utils.tensorboard import SummaryWriter

class SkipCombination_DownSample(torch.nn.Module):
    def __init__(self, residual_block, in_chan, out_chan, stride):
        super().__init__()
        self.residual_block = residual_block
        # downsampling block 
        self.downsample = nn.Sequential(nn.Conv2d(in_channels = in_chan, out_channels = out_chan, kernel_size=1, stride=stride),
                                            nn.BatchNorm2d(out_chan))
    def forward(self, input_data):
        return self.residual_block(input_data) + self.downsample(input_data)

class SkipCombination(torch.nn.Module):
    def __init__(self, residual_block, in_chan, out_chan, stride):
        super().__init__()
        self.residual_block = residual_block
    def forward(self, input_data):
        return self.residual_block(input_data) + input_data


class MyResNet34(torch.nn.Module):
    def __init__(self):
        super().__init__()
        ## Configuration variables
        self.minibatchSize = 100
        self.epochs = 10
        self.learningRate = 0.001
        self.num_layers = 34
        self.image_channels = 1
        self.in_channels = 64
        ## Layers
        # Input images are 28x28
        self.input_conv = nn.Sequential(nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),
          nn.BatchNorm2d(64),
          nn.ReLU(),
          nn.MaxPool2d(kernel_size=3, stride=1, padding=1))
        
        # ResNetLayers
        self.layers = [3, 4, 6, 3]
        self.layer1 = self.make_layers(self.num_layers, self.layers[0], middle_channels=64, stride=1, skip = True)
        self.layer2 = self.make_layers(self.num_layers, self.layers[1], middle_channels=128, stride=2, skip = True)
        self.layer3 = self.make_layers(self.num_layers, self.layers[2], middle_channels=256, stride=2, skip = True)
        self.layer4 = self.make_layers(self.num_layers, self.layers[3], middle_channels=512, stride=2, skip = True)
        #self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        # Fully connected layers
        self.fc = torch.nn.Sequential(
            #torch.nn.Linear(512,10),
            torch.nn.Dropout(0.5),
            #nn.ReLU(),
            nn.Linear(512,10),
            torch.nn.Softmax(dim=1)
        )
      
        
    
    def forward(self, x):
        # Do foward propagation or predictions
        x = self.input_conv(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = nn.AdaptiveAvgPool2d((1, 1))(x)
        #x = self.avgpool(x)
        conv = x.reshape(x.shape[0], -1)
        return self.fc(conv)


        ## model = MyNetwork()
        ## model.var = 12
        ## model.train(trainImages, trainLAbels, logPath)
        ## model.save(path)
        ## prob = model(images)
    def make_layers(self, num_layers, num_blocks, middle_channels, stride,skip):
        # make layers through the resnet blocks
        resnet_layers = []
        resnet_layers.append(self.resnet_block_forward(SkipCombination,in_chan = self.in_channels, out_chan = middle_channels, stride = stride, skip = skip))
        self.in_channels = middle_channels 
        for i in range(num_blocks - 1):
            resnet_layers.append(self.resnet_block_forward(SkipCombination, in_chan = self.in_channels, out_chan = middle_channels, skip = skip)) 
        return nn.Sequential(*resnet_layers)

   
    def resnet_block_forward(self, SkipCombination, in_chan, out_chan, stride = 1, skip = True):
      # define resnet blocks, if skip = True, then activate skip layer with downsampling
      # if skip = False, then activate skip layer without downsampling
        if skip == True:
          skip_comb = SkipCombination_DownSample(
            torch.nn.Sequential(
            nn.Conv2d(in_channels = in_chan, out_channels = out_chan, kernel_size=3, stride = stride, padding=1),
            nn.BatchNorm2d(out_chan),
            torch.nn.ReLU(),
            nn.Conv2d(in_channels = out_chan, out_channels = out_chan, kernel_size=3, stride = 1, padding=1),
            nn.BatchNorm2d(out_chan),
    
            ),in_chan, out_chan, stride
          )
        else:
          skip_comb = SkipCombination(
            torch.nn.Sequential(
            nn.Conv2d(in_channels = in_chan, out_channels = out_chan, kernel_size=3, stride = stride, padding=1),
            nn.BatchNorm2d(out_chan),
            torch.nn.ReLU(),
            nn.Conv2d(in_channels = out_chan, out_channels = out_chan, kernel_size=3, stride = 1, padding=1),
            nn.BatchNorm2d(out_chan),
    
            ),in_chan, out_chan, stride
          )
        return skip_comb

        

    def trainModel(self, trainImages, trainLabels, validationImages, validationLabels,  logPath):
        nTrainImages = trainImages.shape[0]
        nValidateImages = validationImages.shape[0]
        # Configuring minibatches
        nTrainingBatches = nTrainImages // self.minibatchSize
        nValidationBatches = nValidateImages // self.minibatchSize
        if nTrainingBatches * self.minibatchSize < nTrainImages:
            nTrainingBatches += 1
        ## Configuring device
        device = torch.device('cuda:0')
        model = self
        model.to(device=device)
        # Optimization components
        # optimizer
        optimizer = torch.optim.SGD(model.parameters(), lr=self.learningRate, 
momentum=0.5)
        # loss
        #loss = torch.nn.NLLLoss()
        loss = torch.nn.CrossEntropyLoss()
        # logger
        writer = SummaryWriter(logPath)
        ## writer.add_graph(model, [images])
        for epoch in range(self.epochs):
            # For every epoch
            # Make sure that we are in training mode
            print('The ', epoch + 1, 'th epoch:')
            model.train()
            epochLoss = 0
            epochAccuracy = 0
            
            for batch in range(nTrainingBatches):
                    
                # Discard previous gradient if any
                optimizer.zero_grad()
                # input
                x = torch.tensor(trainImages[batch*self.minibatchSize:
(batch+1)*self.minibatchSize, :, :, :],
                    device=device, dtype=torch.float32)
                # ground truth
                y = torch.tensor(trainLabels[batch*self.minibatchSize:
(batch+1)*self.minibatchSize],
                    device=device, dtype=torch.int64)
                # Forward pass for the current minibatch
                y_pred = model(x)
                bacthLoss = loss(y_pred, y)
                # Backpropagation
                bacthLoss.backward()
                # Move!
                optimizer.step()
                # Update epoch loss
                epochLoss += bacthLoss.data * x.shape[0] / nTrainImages
                # Evaluation classification accuracy
                labels_pred = torch.argmax(y_pred, dim=1)
                correct = (y == labels_pred).float()
                accuracy = correct.sum() / correct.numel() # for this minibatch
                epochAccuracy += accuracy * 100 * x.shape[0] / nTrainImages
                print(' - Batch {:05d}/{:05d}. Loss: {:.5f}'.format(batch, 
nTrainingBatches, bacthLoss.data), end='\r')
            
            
            # Validation Loss as well as accuracy
            model.eval()
            validationLoss = 0
            validationAccuracy = 0
            for val_batch in range(nValidationBatches):
                # input
                x_validation = torch.tensor(validationImages[val_batch*self.minibatchSize:
(val_batch+1)*self.minibatchSize, :, :, :],
                    device=device, dtype=torch.float32)
                # ground truth
                y_validation = torch.tensor(validationLabels[val_batch*self.minibatchSize:
(val_batch+1)*self.minibatchSize],
                    device=device, dtype=torch.int64)
                # Forward pass for the current minibatch
                y_pred_validation = model(x_validation)
                bacthLoss_validation = loss(y_pred_validation, y_validation)
                # Update epoch loss
                validationLoss += bacthLoss_validation.data * x_validation.shape[0] / nValidateImages
                # Evaluation classification accuracy
                labels_pred_validation = torch.argmax(y_pred_validation, dim=1)
                correct = (y_validation == labels_pred_validation).float()
                accuracy = correct.sum() / correct.numel() # for this minibatch
                validationAccuracy += accuracy * 100 * x_validation.shape[0] / nValidateImages
            
            
            print('#### Epoch {:05d}/{:05d}. Loss: {:.5f}'.format(epoch, 
self.epochs, epochLoss),'#### Epoch {:05d}/{:05d}. Accuracy: {:.5f}'.format(epoch, 
self.epochs, epochAccuracy), 'Valiadtion Loss: {:.5f}'.format(validationLoss),'Valiadtion Accuracy: {:.5f}'.format(validationAccuracy))
            
            writer.add_scalar('Loss/Training loss', epochLoss, epoch)
            writer.add_scalar('Accuracy/Training accuracy', epochAccuracy, epoch)
            writer.add_scalar('Loss/Validation loss', validationLoss, epoch)
            writer.add_scalar('Accuracy/Validation accuracy', validationAccuracy, epoch)
            ## Validation happens here
        writer.close()
        
    def save(self, path):
        # Save the model
        torch.save(self, path)